There's a wide variety of [metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) for measuring model performance. Which one to look at should be informed by the problem you're trying to solve. In this case, simple classification metrics like precision, recall, and their combination, f1-score, are useful for assessing how well our model is able to identify truly promising call targets as such.

An understanding of our model's performance gained from inspecting such metrics is the foundation for drawing meaningful conclusions from the model interpretability techniques we'll discuss below: Interpreting the working mechanisms of a poorly performing model can be helpful for model debugging, for example, but is not at all suited for deriving insights on the underlying phenomena.
