The obvious first question after inspecting the model predictions and performance is: Which features does the model use to make predictions? [Permutation Feature Importance](https://christophm.github.io/interpretable-ml-book/feature-importance.html) is one straightforward way to answer this question: Just randomly shuffle a feature's values and measure how much the model's performance deteriorates. The bigger the performance drop, the more important the feature. To get a somewhat robust estimate of feature importance, each feature is permuted repeatedly and the performance drop is logged on each iteration. The Boxplot on the right shows the distribution of the importance estimates of our four features.

As expected, the `PredictiveFeature` comes out on top. But what's going on with `PredictiveFeatureCorrelated`?
